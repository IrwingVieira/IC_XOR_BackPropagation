# ImplementaÃ§Ã£o de MLP com Backpropagation - Problema XOR

Este repositÃ³rio contÃ©m o cÃ³digo desenvolvido durante o projeto de IniciaÃ§Ã£o CientÃ­fica sobre Redes Neurais Artificiais. O objetivo principal foi implementar um **Multilayer Perceptron (MLP)** para resolver o problema nÃ£o-linearmente separÃ¡vel do **XOR**.

## ğŸ¯ Objetivo
Demonstrar e compreender matematicamente o funcionamento do algoritmo **Backpropagation** e como camadas ocultas permitem que uma rede neural resolva problemas que modelos lineares (como Perceptron simples e Adaline) nÃ£o conseguem.

## ğŸ› ï¸ Tecnologias Utilizadas
* **Python 3**
* **NumPy:** Para todas as operaÃ§Ãµes matriciais e Ã¡lgebra linear (dot product, transposiÃ§Ã£o, etc).
* **Matplotlib:** Para visualizaÃ§Ã£o dos dados e plotagem da fronteira de decisÃ£o.

## ğŸ§  Arquitetura da Rede
A rede implementada possui a seguinte topologia:
* **Camada de Entrada:** 2 neurÃ´nios (Entradas $x_1$ e $x_2$).
* **Camada Oculta:** 2 neurÃ´nios (AtivaÃ§Ã£o Sigmoide).
* **Camada de SaÃ­da:** 1 neurÃ´nio (AtivaÃ§Ã£o Sigmoide).

## ğŸš€ Como Executar

1. Certifique-se de ter o Python e as bibliotecas instaladas:
   ```bash
   pip install numpy matplotlib